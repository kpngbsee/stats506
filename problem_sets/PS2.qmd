---
title: "PS2"
format:
  html:
    code-overflow: wrap
    embed-resources: true
    theme: simplex
---

## Problem 1

a. 
``` {r}
# rm(list=ls())

# loop
random_walk1 <- function(n) {
  probs <- runif(n)
  
  # start at 0 
  position <- 0
  
  for (i in 1:n) {
    # move +1 or -1 with 50/50 probability
    if (probs[i] < 0.5) {
      # if +1 is chosen, 5% of the time (0.05 * 0.5) move +10
      if (probs[i] < 0.025) {
        position <- position + 10
      } else {
        position <- position + 1
      }
    } else {
      # if -1 is chosen, 20% of the time (0.20 * 0.5) move -3
      if (probs[i] > 0.9) {
        position <- position - 3
      } else {
        position <- position - 1
      }
    }
  }
  
  return(position)
}

# vectorized
random_walk2 <- function(n) {
  probs <- runif(n)
  
  steps <- rep(1, times=n)
  steps[probs < 0.025] <- 10
  steps[probs > 0.5] <- -1
  steps[probs > 0.9] <- -3
  
  return(sum(steps))
}

# apply
random_walk3 <- function(n) {
  probs <- runif(n)
  
  steps <- sapply(1:n, function(i) {
    if (probs[i] < 0.5) {
      if (probs[i] < 0.025) {
        return(10)
      } else {
        return(1)
      }
    } else {
      if (probs[i] > 0.9) {
       return(-3)
      } else {
        return(-1)
      }
    }
  })
  
  return(sum(steps))
}

random_walk1(10)
random_walk2(10)
random_walk3(10)
random_walk1(1000)
random_walk2(1000)
random_walk3(1000)
```

b. 
``` {r}
non_random_walk1 <- function(n) {
  
  # remove randomization and generate probabilities
  set.seed(1)
  probs <- runif(n)
  
  # start at 0 
  position <- 0
  
  for (i in 1:n) {
    # move +1 or -1 with 50/50 probability
    if (probs[i] < 0.5) {
      # if +1 is chosen, 5% of the time (0.05 * 0.5) move +10
      if (probs[i] < 0.025) {
        position <- position + 10
      } else {
        position <- position + 1
      }
    } else {
      # if -1 is chosen, 20% of the time (0.20 * 0.5) move -3
      if (probs[i] > 0.9) {
        position <- position - 3
      } else {
        position <- position - 1
      }
    }
  }
  
  return(position)
}

non_random_walk2 <- function(n) {
  
  # remove randomization and generate probabilities
  set.seed(1)
  probs <- runif(n)
  
  steps <- rep(1, times=n)
  steps[probs < 0.025] <- 10
  steps[probs > 0.5] <- -1
  steps[probs > 0.9] <- -3
  
  return(sum(steps))
}

non_random_walk3 <- function(n) {
  
  # remove randomization and generate probabilities
  set.seed(1)
  probs <- runif(n)
  
  steps <- sapply(1:n, function(i) {
    if (probs[i] < 0.5) {
      if (probs[i] < 0.025) {
        return(10)
      } else {
        return(1)
      }
    } else {
      if (probs[i] > 0.9) {
       return(-3)
      } else {
        return(-1)
      }
    }
  })
  
  return(sum(steps))
}

non_random_walk1(10)
non_random_walk2(10)
non_random_walk3(10)
non_random_walk1(1000)
non_random_walk2(1000)
non_random_walk3(1000)
```

c. 
``` {r}
# install.packages("microbenchmark")
library(microbenchmark)
microbenchmark(random_walk1(1000), random_walk2(1000), random_walk3(1000))
microbenchmark(random_walk1(100000), random_walk2(100000), random_walk3(100000))
```

d.

For this example, I will use the vectorized random walk function to reduce runtime. As seen from part (b), each function can produce the same result while controlling for randomization, so the vectorized function will not return a different result from the other functions.
``` {r}
ns <- c(10, 100, 1000)

estimate_random_walk <- function(n, reps = 10000) {
  return(replicate(reps, random_walk2(n)))
}

position_probs <- vector(length = length(ns))

for (i in seq_along(ns)) {
  random_walks <- estimate_random_walk(ns[i])
  position_probs[i] <- mean(random_walks == 0)
}

position_probs
```

## Problem 2

``` {r}
estimate_cars <- function() {
  num_cars <- rep(0, times = 24)
  num_cars[1:8] <- rpois(length(num_cars[1:8]), lambda=1)
  num_cars[10:18] <- rpois(length(num_cars[10:18]), lambda=8)
  num_cars[19:24] <- rpois(length(num_cars[19:24]), lambda=12)
  num_cars[c(9,18)] <- rnorm(length(num_cars[c(9,18)]), mean = 60, sd = sqrt(12))
  return(sum(num_cars))
}

reps <- 10000
estimated_cars <- replicate(reps, estimate_cars())
mean(estimated_cars)
```

## Problem 3
``` {r}
youtube <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')
```

a. 
``` {r}
dim(youtube)
colnames(youtube)
youtube_new <- youtube[, -c(2, 3, 4, 12, 14, 20, 21, 22, 23, 24)]
dim(youtube_new)
colnames(youtube_new)
```

b.
From the numerical summary, we can see NA values, so I will clean them here in this step.
``` {r}
summary(youtube_new[, 10:14])
youtube_clean <- na.omit(youtube_new)

par(mfrow=c(2,3))
hist(youtube_clean$view_count, breaks=12)
hist(youtube_clean$like_count, breaks=12)
hist(youtube_clean$dislike_count, breaks=12)
hist(youtube_clean$favorite_count, breaks=12)
hist(youtube_clean$comment_count, breaks=12)

pairs(youtube_clean[, 10:14])
```

``` {r}
youtube_clean$log_views    <- log1p(youtube_clean$view_count)
youtube_clean$log_likes    <- log1p(youtube_clean$like_count)
youtube_clean$log_dislikes <- log1p(youtube_clean$dislike_count)
youtube_clean$log_comments <- log1p(youtube_clean$comment_count)
```

c. 
``` {r}
predictors <- c("funny", "show_product_quickly", "patriotic",
                "celebrity", "danger", "animals", "use_sex", "year")

model_views <- lm(log_views ~ ., data = youtube_clean[, c("log_views", predictors)])
model_likes <- lm(log_likes ~ ., data = youtube_clean[, c("log_likes", predictors)])
model_dislikes <- lm(log_dislikes ~ ., data = youtube_clean[, c("log_dislikes", predictors)])
model_comments <- lm(log_comments ~ ., data = youtube_clean[, c("log_comments", predictors)])

summary(model_views)
summary(model_likes)
summary(model_dislikes)
summary(model_comments)
```

d. 
``` {r}
X <- model.matrix(log_views ~ ., data = youtube_clean[, c("log_views", predictors)])
y <- as.numeric(youtube_clean$log_views)

solve(t(X) %*% X) %*% t(X) %*% y
coef(model_views)
```

From the above, we can see that the results are the same.