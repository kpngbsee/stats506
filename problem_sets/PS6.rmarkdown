---
title: "PS6"
format:
  html:
    code-overflow: wrap
    embed-resources: true
    theme: simplex
---


## Problem 1
In the notes, we defined a C_mean function. Using this as a template, implement a C_moment function that returns the kth central moment. Generate a vector of moderate length and show that you are able to replicate the results of e1071::moment.

``` {r}
# rm(list=ls())
library(Rcpp)

cppFunction("
double C_moment(NumericVector x, 
                int order = 1) {
  
  double sum = 0;
  for (int i = 0; i < x.length(); ++i){
     sum += pow(x[i], order);
  }
  return(sum / x.length());
}")
```

``` {r}
# install.packages("e1071")
library(e1071)

x <- rnorm(100)
cat("Order = 1: \nC_moment: ", C_moment(x), "\ne1071 moment: ", moment(x))
cat("Order = 2: \nC_moment: ", C_moment(x, order=2), "\ne1071 moment: ", moment(x, order=2))
```


## Problem 2
a. Write a class bootstrapWaldCI that produces a CI using bootstrap, similar to waldCI.

``` {r}
library(parallel)

source("data/ps6-waldci.R")

bootstrapWaldCI <- setClass("bootstrapWaldCI",
                      contains = "waldCI",
                      slots = c(f = "function",
                                data = "data.frame",
                                reps = "numeric",
                                boot = "numeric",
                                compute = "character"))

#' Bootstrap Helper Function
#'
#' @param f a function
#' @param data dataframe
#'
#' @returns the result of the bootstrap
boot <- function(f, data) {
  data <- data[sample(1:nrow(data), replace = TRUE), ]
  return(f(data))
}

#' Construct a "bootstrapWaldCI" object
#'
#' @param f a function
#' @param data dataframe
#' @param reps number of bootstrap repetitions
#' @param level confidence level
#' @param compute serial (no parallel processing) or parallel (using sockets)
#'
#' @returns "bootstrapWaldCI" object
#' @export
makeBootstrapCI <- function(f, 
                            data, 
                            reps = 1000, 
                            level = 0.95, 
                            compute = "serial") {
  
  boot <- 0
  
  if (compute == "serial") {

    boot <- sapply(seq_len(reps), function(x) boot(f, data))

  } else if (compute == "parallel") {
    
    # because i am on windows
    # i have to use sockets
    cl <- makeCluster(4)
    boot <- parSapply(cl, seq_len(reps), function(x) boot(f, data))
    stopCluster(cl)

  } else {
    stop("compute must be 'serial' or 'parallel'")
  }
  
  # fill in waldCI slots
  
  m <- mean(boot)
  se <- sd(boot)

  new("bootstrapWaldCI",
      level = level,
      mean  = m,
      sterr = se,
      f = f,
      data = data,
      reps = reps,
      boot = boot,
      compute = compute)
}

##' Performs a new bootstrap
##' @param object a "bootstrapWaldCI" object
##' @return a "bootstrapWaldCI" object
##' @export
setGeneric("rebootstrap", function(object) {
  standardGeneric("rebootstrap")
})
setMethod("rebootstrap", "bootstrapWaldCI", function(object) {
  if (object@compute == "serial") {

    boot <- sapply(seq_len(object@reps), function(x) boot(object@f, object@data))

  } else if (object@compute == "parallel") {

    cl <- makeCluster(4)
    boot <- parSapply(cl, seq_len(object@reps), function(x) boot(object@f, object@data))
    stopCluster(cl)

  } else {
    stop("compute must be 'serial' or 'parallel'")
  }
    

  m  <- mean(boot)
  se <- sd(boot)
  z  <- qnorm(1 - (1 - object@level)/2)
  
  object@mean  <- m
  object@sterr <- se
  object@boot <- boot
  
  return(object)
  }
)
```


b. Show your code works by executing the following:

``` {r}
ci1 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000)
ci1
rebootstrap(ci1)
```


c. Write a function called dispCoef that takes in data (based upon mtcars; it must take in a generic data for the bootstrap) and fits the model: mpg ~     cyl + disp + wt. It should return the coefficient associated with disp. Execute the following:


``` {r}
#' Takes in data and fits a model
#'
#' @param data dataframe
#'
#' @returns  coefficient associated with disp
dispCoef <- function(data) {
  model <- lm(mpg ~ cyl + disp + wt, data = data)
  coef(model)["disp"]
}
```

``` {r}
ci2 <- makeBootstrapCI(dispCoef,
                       mtcars,
                       reps = 1000)
ci2
rebootstrap(ci2)
```


## Problem 3
Generate artificial data by running the code in this script. Do not include this script in your submitted PDF; either use source() or save/load to get the data into R.


``` {r}
source("data/ps6-problem3.R")
head(df)
```


a. Fit one model per country. Fit a mixed effects logistic regression model, predicting course completion based upon prior GPA, number of forum posts, number of quiz attempts, and a random effect for device type. Standardize the predictors within each country. Generate some sort of visualization of the estimated coefficients for number of forum posts in each country.

Report the running time (from system.time) for each of the 6 models.

``` {r}
library(dplyr)

# standardize predictors
df_std <- df %>%
  group_by(country) %>%
  mutate(
    gpa_std = scale(prior_gpa)[,1],
    forum_posts_std = scale(forum_posts)[,1],
    quiz_attempts_std = scale(quiz_attempts)[,1]
  ) %>%
  ungroup()
```

``` {r}
library(lme4)

# fit models per country
df_list <- split(df_std, df_std$country)
countries <- names(df_list)

# list of models
models <- vector("list", length(countries))
names(models) <- countries

# times for each model
times <- numeric(length(countries))
names(times) <- countries

system.time({
  for (i in seq_along(countries)) {
    data <- df_list[[i]]
    t <- system.time({
      model <- glmer(
        completed_course ~ gpa_std + forum_posts_std + quiz_attempts_std + (1 | device_type),
        family = binomial,
        data = data
      )
    })
    models[[i]] <- model
    times[i] <- t["elapsed"]
  }
})
  
```

``` {r}
coef_df <- data.frame(
  country = names(models),
  time = times,
  coef = sapply(models, function(m) fixef(m)["forum_posts_std"]),
  se  = sapply(models, function(m) sqrt(diag(vcov(m)))["forum_posts_std"])
)
coef_df
```

The above is a dataframe that displays the runtime for each model, the coefficient estimate, and the standard error.


``` {r}
coef_df$lower <- coef_df$coef - 1.96 * coef_df$se
coef_df$upper <- coef_df$coef + 1.96 * coef_df$se

library(ggplot2)

ggplot(coef_df, aes(x = coef, y = rownames(coef_df))) +
  geom_point(shape=15, size=3) +
  geom_linerange(aes(xmin = lower, xmax = upper)) +
  theme_minimal() +
  labs(
    title = "Estimated Coefficients for Number of Forum Posts by Country",
    y = "Country",
    x = "Estimated Coefficient"
  )

```


b. Devise an approach that minimizes the running time of your script. Report the running time of your entire script (running models and estimating coefficients; no need for a new plot). Do not use a different package for the models. Show that the results match those from part a).

``` {r}
cl <- makeCluster(6)
clusterExport(cl, "df_list")
clusterEvalQ(cl, library(lme4))

system.time({
  parallel_results <- parLapply(cl, countries, function(cty) {
    data <- df_list[[cty]]
    
    t <- system.time({
      model <- glmer(
        completed_course ~ gpa_std + forum_posts_std + quiz_attempts_std + (1 | device_type),
        family = binomial,
        data = data
      )
    })
    
    list(country = cty, model = model, time = t["elapsed"])
  })
})

stopCluster(cl)
```

From the above, the total elapsed time is similar to the runtime of the model with the slowest runtime in part (a).


``` {r}
parallel_time <- sapply(parallel_results, `[[`, "time")

parallel_coef <- sapply(parallel_results, function(x) fixef(x$model)["forum_posts_std"])

coef_df$parallel_time <- parallel_time
coef_df$parallel_coef <- parallel_coef

coef_df[,c("country", "time", "parallel_time", "coef", "parallel_coef")]
```

From the above, we can see they both produced the same coefficient estimates, while individual model times were similar (in other words, the runtime for each model were the same between serial and parallel, but the total elapsed time differs.)

## Problem 4

For this problem, I referred to the PS4 solutions and followed the approach used there, but using data.table. 

``` {r}
library(data.table)
atp_matches <- fread("data/atp_matches_2019.csv")
```


a. How many tournaments took place in 2019?

``` {r}
# initial unique tournaments
tourneys <- unique(atp_matches[, .(tourney_name)])
nrow(tourneys)

# collapse duplicate davis cup entries
tourneys[, tourney_name := sub("Davis.*", "Davis Cup", tourney_name)]

# actual unique tournaments
tourneys <- unique(tourneys)
nrow(tourneys)
```

69 unique tournaments took place in 2019. 

b. Did any player win more than one tournament? If so, how many players won more than one tournament, and how many tournaments did the most winning player(s) win?

``` {r}
# following ps4 solutions:
# arrange by tourney_name, descending match_num
setorder(atp_matches, tourney_name, -match_num)

# group by tourney_name, slice(1), select winner_name
winners <- atp_matches[, .SD[1], by = tourney_name][
  , .(winner_name)
]

# group by winner_name, find count of wins
# filter by wins > 1, descending wins
multiwinners <- winners[
  , .(wins = .N), by = winner_name
][
  wins > 1
][
  order(-wins)
]

multiwinners
nrow(multiwinners)
```

17 players won more than one tournament. Rafael Nadal won the most, with 9 tournament wins. 

c. Is there any evidence that winners have more aces than losers?

``` {r}
# following ps4 solutions,

# select w_ace, l_ace (remove NA)
aces <- atp_matches[, .(w_ace, l_ace)]
aces <- aces[!is.na(w_ace) & !is.na(l_ace)]

# create variable win_more
aces[, win_more := w_ace > l_ace]

# perform one-sample prop test vs 0.5
test <- prop.test(sum(aces$win_more), nrow(aces), p = 0.5)
test
```

The p value is 4.952e-14 < 0.05, which indicates that winners have more aces than losers.

d. Identify the player(s) with the highest win-rate. (Note that this is NOT asking for the highest number of wins.) Restrict to players with at least 5 matches.

``` {r}
# pivot_longer winners and losers
long <- rbindlist(list(
  atp_matches[, .(player = winner_name, winner = TRUE)],
  atp_matches[, .(player = loser_name, winner = FALSE)]
))

# group by player, find winrate
# filter matches > 5, descending winrate
rates <- long[
  , .(
      matches = .N,
      winrate = mean(winner)
    ),
  by = player
][
  matches > 5
][
  order(-winrate)
]

# slice(1:2)
rates[1:2]
```

The player with the highest winrate of 87% is Rafael Nadal.

## Attribution

* e1071 moment function: https://www.rdocumentation.org/packages/e1071/versions/1.7-16/topics/moment

* Forest plot: https://www.khstats.com/blog/forest-plots/
